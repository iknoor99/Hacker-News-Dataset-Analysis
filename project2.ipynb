{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Project 2\n",
    "# Written by: Harsh Deep Kour(40082906) and Iknoor Singh Arora(40082312)\n",
    "# For COMP 6721 Section: FK (1779) - Fall 2019\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'/Users/harshkour/Desktop/AI-P2/hn2018_2019-2.csv')\n",
    "data = pd.read_csv(r'hn2018_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in Training are: 4280\n"
     ]
    }
   ],
   "source": [
    "traindata=data[(data['Created At'] > '2018-01-01') & (data['Created At'] < '2019-01-01')]\n",
    "traindatalen=len(traindata)\n",
    "print(\"No. of records in Training are: \" + str(traindatalen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in Training are: 3211\n"
     ]
    }
   ],
   "source": [
    "testdata=data[(data['Created At'] >= '2019-01-01')]\n",
    "print(\"No. of records in Training are: \" + str(len(testdata)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Post_Type_required = ['story','ask_hn','show_hn','poll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for Pos tag mapping \n",
    "def pos_mapping(word_tag):\n",
    "        \n",
    "    if word_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif word_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif word_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif word_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.ADV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Vocabulary is :12935\n",
      "Number of Bigrams in Vocabulary are: 8784\n",
      "No. of words removed are :302\n"
     ]
    }
   ],
   "source": [
    "#Creating vocabulary for training data\n",
    "lemmat = WordNetLemmatizer()\n",
    "\n",
    "vocablist=[]\n",
    "bigramslist = []\n",
    "unique_bigrams =[]\n",
    "nonvocablist = []\n",
    "nonvocab_unique = []\n",
    "#english_vocab = nltk.corpus.words.words()\n",
    "\n",
    "\n",
    "for i, row in traindata.iterrows():\n",
    "    final=' '\n",
    "    bigrams_final = []\n",
    "    unigram = []\n",
    "    nonunigram = []\n",
    "    vocab = []\n",
    "    pattern = '[\\w]+'\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    title = row.Title\n",
    "    title = title.replace(\"'\",\"\")\n",
    "    list_wordtokenized=tokenizer.tokenize(title)# tokenization using regextokenizer\n",
    "    posttag_list = pos_tag(list_wordtokenized)#finding pos tags\n",
    "    bigrams = list(nltk.bigrams(posttag_list))#libray for bigram creation\n",
    "    \n",
    "    #creating bygrams for pos_tags starting with N\n",
    "    for (w1,w2) in bigrams :\n",
    "        \n",
    "        flagw1 = False\n",
    "        flagw2 = False\n",
    "        flag_w1 = False\n",
    "        flag_w2 = False\n",
    "        posw1 = pos_mapping(w1[1])\n",
    "        posw2 = pos_mapping(w2[1])\n",
    "        lemword1=(lemmat.lemmatize(w1[0],posw1)).lower()\n",
    "        lemword2=(lemmat.lemmatize(w2[0],posw2)).lower()\n",
    "        \n",
    "        \n",
    "        if('_' in lemword1):\n",
    "            word1 = lemword1.replace(\"_\",\"\")\n",
    "            if word1.isalpha():\n",
    "                flag_w1 = True \n",
    "        if('_' in lemword2):\n",
    "            word2 = lemword2.replace(\"_\",\"\")\n",
    "            if word2.isalpha():\n",
    "                flag_w2 = True \n",
    "        #if (lemword1.isalpha() and len(lemword1)!=1) or flag_w1 or (len(lemword1)==1 and (lemword1 == 'a' or lemword1 == 'i')):\n",
    "        if (lemword1.isalpha()) or flag_w1:\n",
    "            flagw1 = True\n",
    "        else:\n",
    "            nonvocablist.append(lemword1) \n",
    "        #if (lemword2.isalpha() and len(lemword2)!=1) or flag_w2 or (len(lemword2)==1 and (lemword2 == 'a' or lemword2 == 'i')):\n",
    "        if (lemword2.isalpha()) or flag_w2:    \n",
    "            flagw2 = True\n",
    "        else:\n",
    "            nonvocablist.append(lemword2)\n",
    "            \n",
    "        if posw1 == 'n' and posw2 == 'n' and flagw1 and flagw2:\n",
    "            x = \"%s %s\" % (lemword1.strip(),lemword2.strip())\n",
    "            bigrams_final.append(x)\n",
    "            nonunigram.append(lemword1)\n",
    "            nonunigram.append(lemword2)\n",
    "        else:\n",
    "            if flagw1:\n",
    "                unigram.append(lemword1)\n",
    "            if flagw2:\n",
    "                unigram.append(lemword2)\n",
    "                \n",
    "    unigram_final = list(set(unigram) - set(nonunigram))\n",
    "    vocab.extend(unigram_final)\n",
    "    vocab.extend(bigrams_final)\n",
    "    vocablist.extend(vocab)\n",
    "    bigramslist.extend(bigrams_final)\n",
    "    \n",
    "    traindata.at[i, 'Title']= vocab\n",
    "\n",
    "unique_bigrams = np.unique(bigramslist)\n",
    "vocab_unique=np.unique(vocablist)\n",
    "vocab_unique=list(vocab_unique)\n",
    "vocab_unique.sort()\n",
    "nonvocab_unique=np.unique(nonvocablist)\n",
    "nonvocab_unique=list(nonvocab_unique)\n",
    "nonvocab_unique.sort()\n",
    "print(\"Length of Training Vocabulary is :\" + str(len(vocab_unique)))\n",
    "print(\"Number of Bigrams in Vocabulary are: \" + str(len(unique_bigrams)))\n",
    "print(\"No. of words removed are :\" + str(len(nonvocab_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a vocabulary file\n",
    "vocabfile = open('vocabulary.txt', \"w\",encoding=\"utf-8\")\n",
    "vocabfile.write(\"\\n\".join(str(item) for item in vocab_unique))\n",
    "vocabfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a remove words file \n",
    "nonvocabfile = open('remove_word.txt', \"w\",encoding=\"utf-8\")\n",
    "nonvocabfile.write(\"\\n\".join(str(item) for item in nonvocab_unique))\n",
    "nonvocabfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      "2744\n",
      "ask_hn\n",
      "105\n",
      "show_hn\n",
      "1406\n",
      "poll\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "type_dict = {} # 2d dictionary for each word's frequency corresponding to class\n",
    "\n",
    "new_list = Post_Type_required\n",
    "prob_type_dict={} # dictionary for class score\n",
    "\n",
    "for type_value in new_list:\n",
    "    all_rows = traindata.loc[traindata['Post Type'] == type_value]\n",
    "    print(type_value)\n",
    "    print(len(all_rows))\n",
    "    prob_type_dict[type_value]=len(all_rows)/traindatalen\n",
    "    type_dict[type_value]=pd.Series(np.concatenate([x for x in all_rows['Title']])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for creating the model and adding probability values for each class for words in model text file.\n",
    "#It returns main dictionary and test dictionary which has prob and freq corresponding to each word.\n",
    "\n",
    "def model_building(file_name_writeread,file_name_write,smooth_factor):\n",
    "    file_text = open(file_name_writeread, \"w\", encoding=\"utf-8\")\n",
    "    main_dict = {} # 2d dictionary type - word - freq/classtype +probability/classtype\n",
    "    for post_type,val in type_dict.items():\n",
    "        sumval= sum(type_dict[post_type])\n",
    "        main_dict[post_type] = {}\n",
    "        word_dict = {}\n",
    "        for word in vocab_unique:\n",
    "            word_freq=0\n",
    "            if(word in type_dict[post_type]):     \n",
    "                word_freq=type_dict[post_type][word]\n",
    "\n",
    "            probab=(word_freq+smooth_factor)/(sumval+len(vocab_unique))\n",
    "            word_dict[word] = str(word_freq) + \"  \" + str(probab)\n",
    "            \n",
    "        main_dict[post_type] = word_dict\n",
    "\n",
    " \n",
    "    post_type_list = []\n",
    "    counter = 0\n",
    "    test_dict = {}\n",
    "    for word in vocab_unique:\n",
    "        prob_word = []\n",
    "        counter = counter + 1\n",
    "        freprobstr = \"\"\n",
    "        for keys in main_dict.keys():\n",
    "            #print(\"key is \" + str(keys))\n",
    "            w_dict = main_dict[keys]\n",
    "            freqprob = w_dict[word].split(\"  \")\n",
    "\n",
    "            prob_word.append(float(freqprob[1]))\n",
    "            if freprobstr == \"\":\n",
    "                freprobstr =  w_dict[word]\n",
    "            else:\n",
    "                freprobstr = \"  \" + freprobstr + \"  \" + w_dict[word]\n",
    "        test_dict[word] = prob_word\n",
    "        word = str(word).strip()   \n",
    "        file_text.write(str(counter) + \"  \" + word + \"  \" + freprobstr.strip() + \"\\r\\n\")  \n",
    "\n",
    "    #print(main_dict)\n",
    "    file_text.close()\n",
    "    return main_dict,test_dict              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating total probability of the words in the title for each class\n",
    "def calcvocabscore(main_dict,test_dict):\n",
    "    Score_dict = {}   \n",
    "    for word in test_dict:\n",
    "        final_classscores_list = []       \n",
    "        probclasslist =  test_dict[word]\n",
    "        word_log0= math.log(probclasslist[0],10)\n",
    "        word_log1= math.log(probclasslist[1],10)\n",
    "        word_log2= math.log(probclasslist[2],10)\n",
    "        word_log3= math.log(probclasslist[3],10)\n",
    "        \n",
    "        final_classscores_list.append(word_log0)\n",
    "        final_classscores_list.append(word_log1)\n",
    "        final_classscores_list.append(word_log2)\n",
    "        final_classscores_list.append(word_log3)\n",
    "        \n",
    "        Score_dict[word] = final_classscores_list\n",
    "    return Score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Implementation and test file generation\n",
    "\n",
    "def naive_bayes(file_name_writeread,file_name_write,main_dict,test_dict,Score_dict):\n",
    "    file_result = open(file_name_write, \"w\",encoding=\"utf-8\")\n",
    "    line_counter=0\n",
    "    predicted_class=[]\n",
    "    actual_class=[]\n",
    "    classes_list=[]   \n",
    "    classscores = []\n",
    "    class_prob_testlist=[]\n",
    "    for class_type in main_dict.keys():\n",
    "        class_prob_testlist.append(class_type)\n",
    "        class_score = prob_type_dict[class_type] # class score\n",
    "        word_log = math.log(class_score,10)\n",
    "        classscores.append(word_log)\n",
    "\n",
    "    for i, row in testdata.iterrows():\n",
    "        final_classscores_str=\"\"\n",
    "        final_classscores_list=[]\n",
    "        \n",
    "        line_counter=line_counter+1\n",
    "        result_string=\"\"\n",
    "        label_correct=testdata.at[i,'Post Type']\n",
    "        \n",
    "        word_log0 = classscores[0]\n",
    "        word_log1 = classscores[1]\n",
    "        word_log2 = classscores[2]\n",
    "        word_log3 = classscores[3]\n",
    "                \n",
    "        title_put=' '\n",
    "        unigram = []\n",
    "        nonunigram = []\n",
    "        vocab = []\n",
    "        pattern = '[\\w]+'\n",
    "        tokenizer = RegexpTokenizer(pattern)\n",
    "        title_put = row.Title\n",
    "        title = title_put.replace(\"'\",\"\")\n",
    "        list_wordtokenized=tokenizer.tokenize(title)\n",
    "        posttag_list = pos_tag(list_wordtokenized)\n",
    "        bigrams = list(nltk.bigrams(posttag_list))\n",
    "        for (w1,w2) in bigrams :       \n",
    "            flagw1 = False\n",
    "            flagw2 = False\n",
    "            flag_w1 = False\n",
    "            flag_w2 = False\n",
    "            posw1 = pos_mapping(w1[1])\n",
    "            posw2 = pos_mapping(w2[1])\n",
    "            lemword1=(lemmat.lemmatize(w1[0],posw1)).lower()\n",
    "            lemword2=(lemmat.lemmatize(w2[0],posw2)).lower()\n",
    "            \n",
    "            if('_' in lemword1):\n",
    "                word1 = lemword1.replace(\"_\",\"\")\n",
    "                if word1.isalpha():\n",
    "                    flag_w1 = True \n",
    "            if('_' in lemword2):\n",
    "                word2 = lemword2.replace(\"_\",\"\")\n",
    "                if word2.isalpha():\n",
    "                    flag_w2 = True \n",
    "            if (lemword1.isalpha()) or flag_w1:\n",
    "                flagw1 = True\n",
    "            else:\n",
    "                nonvocablist.append(lemword1) \n",
    "            if (lemword2.isalpha()) or flag_w2:    \n",
    "                flagw2 = True\n",
    "            else:\n",
    "                nonvocablist.append(lemword2)  \n",
    "            if posw1 == 'n' and posw2 == 'n' and flagw1 and flagw2:\n",
    "                x = \"%s %s\" % (lemword1.strip(),lemword2.strip())\n",
    "                unigram.append(x)\n",
    "                nonunigram.append(lemword1)\n",
    "                nonunigram.append(lemword2)      \n",
    "                if x in test_dict:\n",
    "                    val = Score_dict[x]\n",
    "                    word_log0=word_log0+val[0]\n",
    "                    word_log1=word_log1+val[1]\n",
    "                    word_log2=word_log2+val[2]\n",
    "                    word_log3=word_log3+val[3]\n",
    "                if lemword1 in unigram:\n",
    "                    unigram.remove(lemword1)\n",
    "                    if (lemword1 in test_dict):\n",
    "                        val = Score_dict[lemword1]\n",
    "                        word_log0=word_log0-(val[0])\n",
    "                        word_log1=word_log1-(val[1])\n",
    "                        word_log2=word_log2-(val[2])\n",
    "                        word_log3=word_log3-(val[3])\n",
    "                if lemword2 in unigram:\n",
    "                    unigram.remove(lemword2)\n",
    "                    if (lemword2 in test_dict):\n",
    "                        val = Score_dict[lemword2]\n",
    "                        word_log0=word_log0-(val[0])\n",
    "                        word_log1=word_log1-(val[1])\n",
    "                        word_log2=word_log2-(val[2])\n",
    "                        word_log3=word_log3-(val[3])\n",
    "            else:\n",
    "                if flagw1 and (lemword1 not in unigram) and (lemword1 not in nonunigram):\n",
    "                    unigram.append(lemword1)\n",
    "                    if lemword1 in test_dict:\n",
    "                        val = Score_dict[lemword1]\n",
    "                        word_log0=word_log0+val[0]\n",
    "                        word_log1=word_log1+val[1]\n",
    "                        word_log2=word_log2+val[2]\n",
    "                        word_log3=word_log3+val[3]\n",
    "                if flagw2 and (lemword2 not in unigram) and (lemword2 not in nonunigram):\n",
    "                    unigram.append(lemword2)\n",
    "                    if lemword2 in test_dict:\n",
    "                        val = Score_dict[lemword2]\n",
    "                        word_log0=word_log0+val[0]\n",
    "                        word_log1=word_log1+val[1]\n",
    "                        word_log2=word_log2+val[2]\n",
    "                        word_log3=word_log3+val[3]\n",
    "                   \n",
    "        \n",
    "\n",
    "        final_classscores_list.append(word_log0)\n",
    "        final_classscores_list.append(word_log1)\n",
    "        final_classscores_list.append(word_log2)\n",
    "        final_classscores_list.append(word_log3)\n",
    "        word_log0 = (\"{:12.10f}\".format(word_log0))\n",
    "        word_log1 = (\"{:12.10f}\".format(word_log1))\n",
    "        word_log2 = (\"{:12.10f}\".format(word_log2))\n",
    "        word_log3 = (\"{:12.10f}\".format(word_log3))\n",
    "        if final_classscores_str == \"\":\n",
    "            final_classscores_str = str(word_log0) + \"  \" + str(word_log1)+ \"  \" + str(word_log2)+ \"  \" + str(word_log3)\n",
    "\n",
    "            \n",
    "        max_probscore_index=final_classscores_list.index(max(final_classscores_list))\n",
    "        label_classified=class_prob_testlist[max_probscore_index]\n",
    "        rel=\"\"\n",
    "        if label_classified == label_correct:\n",
    "            rel=\"right\"\n",
    "        else:\n",
    "            rel=\"wrong\"\n",
    "        actual_class.append(label_correct)\n",
    "        predicted_class.append(label_classified)\n",
    "        result_string=result_string+str(line_counter)+\"  \"+str(title_put)+\"  \"+str(label_classified)+\"  \"+str(final_classscores_str)+\"  \"+str(label_correct)+\"  \"+rel\n",
    "        file_result.write(result_string + \"\\r\\n\")\n",
    "    file_result.close()\n",
    "    classes_list= np.unique(actual_class)\n",
    "    return (actual_class,predicted_class,classes_list)\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results analysis\n",
    "\n",
    "def result_analysis(actual_class,predicted_class,experiment,classes_list):\n",
    "    \n",
    "    \n",
    "    experiment=experiment.strip()\n",
    "    \n",
    "    if experiment=='exp1' or experiment=='exp2' or experiment=='exp3'or experiment=='exp4' or experiment=='exp5':\n",
    "        \n",
    "        print(\"experiment:-\",experiment)\n",
    "        print(\"\\n\")\n",
    "        print(\"----confusion matrix----\")\n",
    "        cm = pd.DataFrame(confusion_matrix(actual_class,predicted_class),columns=classes_list,index=classes_list)\n",
    "        print(cm)\n",
    "        print(\"\\n\")\n",
    "        print(\"----classification report----\")\n",
    "        print(classification_report(actual_class,predicted_class ,target_names=classes_list))\n",
    "        print(\"\\n\")\n",
    "        print(\"----Accuracy report----\")\n",
    "        print(accuracy_score(actual_class, predicted_class))\n",
    "\n",
    "    if experiment=='exp5' or experiment=='exp4' :\n",
    "        \n",
    "        accuracy_diffsmooth.append(accuracy_score(actual_class, predicted_class))\n",
    "   \n",
    "    #print(\"accuracy_diffsmooth\",accuracy_diffsmooth)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the experiment no.(exp1/exp2/exp3/exp4/exp5)exp5\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      326     0      112    614\n",
      "poll          0     0        2      4\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       58    870\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.31      0.47      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.88      0.99      0.93      1225\n",
      "       story       0.58      0.94      0.72       928\n",
      "\n",
      "    accuracy                           0.75      3211\n",
      "   macro avg       0.61      0.56      0.53      3211\n",
      "weighted avg       0.83      0.75      0.72      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7511678604796014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      320     0      100    632\n",
      "poll          0     0        2      4\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       51    877\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.30      0.47      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.89      0.99      0.94      1225\n",
      "       story       0.58      0.95      0.72       928\n",
      "\n",
      "    accuracy                           0.75      3211\n",
      "   macro avg       0.62      0.56      0.53      3211\n",
      "weighted avg       0.83      0.75      0.72      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7514792899408284\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      312     0       95    645\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       48    880\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.30      0.46      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.89      0.99      0.94      1225\n",
      "       story       0.57      0.95      0.71       928\n",
      "\n",
      "    accuracy                           0.75      3211\n",
      "   macro avg       0.62      0.56      0.53      3211\n",
      "weighted avg       0.83      0.75      0.71      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7499221426346933\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      307     0       92    653\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       49    879\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.29      0.45      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.57      0.95      0.71       928\n",
      "\n",
      "    accuracy                           0.75      3211\n",
      "   macro avg       0.62      0.56      0.53      3211\n",
      "weighted avg       0.83      0.75      0.71      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7480535658673311\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      305     0       87    660\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1215     10\n",
      "story         0     0       50    878\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.29      0.45      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.57      0.95      0.71       928\n",
      "\n",
      "    accuracy                           0.75      3211\n",
      "   macro avg       0.62      0.56      0.52      3211\n",
      "weighted avg       0.83      0.75      0.71      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.746807848022423\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      298     0       87    667\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       48    880\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.28      0.44      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.56      0.95      0.71       928\n",
      "\n",
      "    accuracy                           0.75      3211\n",
      "   macro avg       0.62      0.56      0.52      3211\n",
      "weighted avg       0.83      0.75      0.71      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7455621301775148\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      296     0       87    669\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       48    880\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.28      0.44      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.56      0.95      0.71       928\n",
      "\n",
      "    accuracy                           0.74      3211\n",
      "   macro avg       0.62      0.56      0.52      3211\n",
      "weighted avg       0.83      0.74      0.71      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7449392712550608\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      292     0       86    674\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       48    880\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.28      0.43      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.56      0.95      0.71       928\n",
      "\n",
      "    accuracy                           0.74      3211\n",
      "   macro avg       0.62      0.55      0.52      3211\n",
      "weighted avg       0.83      0.74      0.71      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7436935534101526\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      289     0       87    676\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       48    880\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.27      0.43      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.56      0.95      0.70       928\n",
      "\n",
      "    accuracy                           0.74      3211\n",
      "   macro avg       0.61      0.55      0.52      3211\n",
      "weighted avg       0.83      0.74      0.70      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7427592650264715\n",
      "experiment:- exp5\n",
      "\n",
      "\n",
      "----confusion matrix----\n",
      "         ask_hn  poll  show_hn  story\n",
      "ask_hn      284     0       88    680\n",
      "poll          0     0        1      5\n",
      "show_hn       0     0     1216      9\n",
      "story         0     0       49    879\n",
      "\n",
      "\n",
      "----classification report----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       1.00      0.27      0.43      1052\n",
      "        poll       0.00      0.00      0.00         6\n",
      "     show_hn       0.90      0.99      0.94      1225\n",
      "       story       0.56      0.95      0.70       928\n",
      "\n",
      "    accuracy                           0.74      3211\n",
      "   macro avg       0.61      0.55      0.52      3211\n",
      "weighted avg       0.83      0.74      0.70      3211\n",
      "\n",
      "\n",
      "\n",
      "----Accuracy report----\n",
      "0.7408906882591093\n",
      "Smooth Factor: \n",
      " [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
      "Accuracy: \n",
      " [0.7511678604796014, 0.7514792899408284, 0.7499221426346933, 0.7480535658673311, 0.746807848022423, 0.7455621301775148, 0.7449392712550608, 0.7436935534101526, 0.7427592650264715, 0.7408906882591093]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program finished\n"
     ]
    }
   ],
   "source": [
    "#Class for performing experiments for different vocab size and smoothing factor\n",
    "experiment= input(\"Enter the experiment no.(exp1/exp2/exp3/exp4/exp5)\").strip()\n",
    "smooth_factor=0.5\n",
    "#baseline experiment\n",
    "if experiment=='exp1':\n",
    "    \n",
    "    file_name_writeread=\"model-2018.txt\"\n",
    "    file_name_write=\"baseline-result.txt\"\n",
    "    \n",
    "    main_dict,test_dict= model_building(file_name_writeread,file_name_write,smooth_factor)\n",
    "    Score_dict = calcvocabscore(main_dict,test_dict)   \n",
    "    actual_class,predicted_class,classes_list=naive_bayes(file_name_writeread,file_name_write,main_dict,test_dict,Score_dict)\n",
    "    result_analysis(actual_class,predicted_class,experiment.strip(),classes_list)\n",
    "    \n",
    "    \n",
    "    print(\"Program finished\")\n",
    "#stopword removal    \n",
    "elif experiment=='exp2':\n",
    "    \n",
    "    stopwords_file=open(r\"Stopwords.txt\", \"r\",encoding=\"utf-8\")\n",
    "    file_cont=stopwords_file.read()\n",
    "    file_cont.replace(\"'\",\"\")\n",
    "    lines=file_cont.splitlines()\n",
    "    \n",
    "    for word in vocab_unique:\n",
    "        if word in lines:\n",
    "            vocab_unique.remove(word)\n",
    "        elif ' ' in word:\n",
    "            bigram = word.split(' ')\n",
    "            for b in bigram:\n",
    "                if (b in lines) and word in vocab_unique:\n",
    "                    vocab_unique.remove(word)       \n",
    "     \n",
    "     \n",
    "    vocab_unique.sort()\n",
    "    file_name_writeread=\"stopword-model.txt\"\n",
    "    file_name_write=\"stopword-result.txt\" \n",
    "    \n",
    "    main_dict,test_dict=model_building(file_name_writeread,file_name_write,smooth_factor)\n",
    "    Score_dict = calcvocabscore(main_dict,test_dict)\n",
    "    actual_class,predicted_class,classes_list=naive_bayes(file_name_writeread,file_name_write,main_dict,test_dict,Score_dict)\n",
    "    result_analysis(actual_class,predicted_class,experiment.strip(),classes_list)\n",
    "    \n",
    "    print(\"Program finished\")\n",
    "    \n",
    "#word-length filtering    \n",
    "elif experiment=='exp3':\n",
    "    \n",
    "    new_vocab=[]\n",
    "    for word in vocab_unique:\n",
    "        if (len(word)>=3 and len(word)<=8):\n",
    "            new_vocab.append(word)\n",
    "    vocab_unique=new_vocab \n",
    "    vocab_unique.sort()\n",
    "    \n",
    "    file_name_writeread=\"wordlength-model.txt\"\n",
    "    file_name_write=\"wordlength-result.txt\"\n",
    "    \n",
    "    main_dict,test_dict=model_building(file_name_writeread,file_name_write,smooth_factor)\n",
    "    Score_dict = calcvocabscore(main_dict,test_dict)\n",
    "    actual_class,predicted_class,classes_list=naive_bayes(file_name_writeread,file_name_write,main_dict,test_dict,Score_dict)\n",
    "    result_analysis(actual_class,predicted_class,experiment.strip(),classes_list)\n",
    "    \n",
    "    print(\"Program finished\")\n",
    "    \n",
    "#frequency filtering   \n",
    "elif experiment=='exp4':\n",
    "    new_vocab_len=[]\n",
    "    accuracy_diffsmooth=[]\n",
    "    total_freq_dict={} \n",
    "     \n",
    "    unique, counts = np.unique(vocablist, return_counts=True)\n",
    "    total_freq_dict = dict(zip(unique, counts))\n",
    "    \n",
    "    vocabset= set(total_freq_dict.keys())\n",
    "    \n",
    "    sorted(total_freq_dict.items(), key=lambda x: x[1])\n",
    "    \n",
    "    freq_removal=['1','l5','l10','l15','l20','p5','p10','p15','p20','p25']\n",
    "    less_flag=False\n",
    "    percent_flag=False\n",
    "    \n",
    "    for freq in freq_removal:\n",
    "        #print(\"Value is ---- \"+ str(freq))\n",
    "        \n",
    "        remove_words=[]\n",
    "        \n",
    "        if len(freq)>1:\n",
    "            if(freq[0]=='l'):\n",
    "                less_flag=True \n",
    "            else:\n",
    "                less_flag=False\n",
    "                percent_flag=True\n",
    "                \n",
    "            freq=int(freq[1:])\n",
    "        \n",
    "        if(percent_flag is True):\n",
    "            dict_len=len(total_freq_dict.items())\n",
    "            num_words=int((freq/100)*dict_len)\n",
    "            #print(num_words)\n",
    "            num_wordst = num_words\n",
    "            list2 = list(total_freq_dict.values())\n",
    "            valuelist, counts = np.unique(list2, return_counts=True)\n",
    "            valuedict = dict(zip(valuelist, counts))\n",
    "            valuetoberemoved = []\n",
    "            lastvalueremoved = 0\n",
    "            #print(list2)\n",
    "            while(num_words>0):\n",
    "                maxval = max(list2)\n",
    "                #print(\"maximum value is \" + str(maxval))\n",
    "                count = valuedict[maxval]\n",
    "                list2 = list(filter(lambda a: a != maxval, list2))\n",
    "                #print(\"count is \" + str(count))\n",
    "                num_words = num_words - count\n",
    "                #print(\"numwords is \" + str(num_words))\n",
    "                if num_words >= 0:\n",
    "                    valuetoberemoved.append(maxval)\n",
    "                else:\n",
    "                    lastvalueremoved = maxval\n",
    "                    #print(\"last value to be removed \" + str(lastvalueremoved))\n",
    "                #print(valuetoberemoved) \n",
    "                \n",
    "                \n",
    "            counting=0\n",
    "            \n",
    "            for word in total_freq_dict:\n",
    "                word_freq = total_freq_dict[word]\n",
    "                if(word_freq in valuetoberemoved) and (word in total_freq_dict) and counting<num_wordst:\n",
    "                    vocabset.discard(word)\n",
    "                    remove_words.append(word)\n",
    "                    counting=counting+1\n",
    "                if counting>=num_wordst:\n",
    "                    break\n",
    "            \n",
    "            #print(remove_words)\n",
    "            \n",
    "            if lastvalueremoved != 0:\n",
    "                for word in total_freq_dict:\n",
    "                    word_freq = total_freq_dict[word]\n",
    "                    if word_freq == lastvalueremoved:\n",
    "                        vocabset.discard(word)\n",
    "                        remove_words.append(word)\n",
    "                        counting=counting+1\n",
    "                        if counting>=num_wordst:\n",
    "                            break\n",
    "                      \n",
    "        else:   \n",
    "            if (less_flag is False) :\n",
    "                for word in total_freq_dict: \n",
    "                    word_freq = total_freq_dict[word]\n",
    "                    if(word_freq == int(freq)):\n",
    "                        if(word in total_freq_dict):\n",
    "                            vocabset.discard(word)\n",
    "                            remove_words.append(word)\n",
    "                      \n",
    "\n",
    "            elif (less_flag is True):\n",
    "                for word in total_freq_dict: \n",
    "                    word_freq = total_freq_dict[word]\n",
    "                    if(word_freq<=freq):\n",
    "                        if(word in total_freq_dict):\n",
    "                            vocabset.discard(word) \n",
    "                            remove_words.append(word) \n",
    "        \n",
    "        vocab_unique = list(vocabset - set(remove_words))\n",
    "        for wor in remove_words:\n",
    "            if wor in total_freq_dict:\n",
    "                del total_freq_dict[wor]\n",
    "        \n",
    "        #print(total_freq_dict)\n",
    "        vocab_unique.sort()\n",
    "        \n",
    "        new_vocab_len.append(len(vocab_unique))\n",
    "\n",
    "        file_name_writeread=\"model-2018.txt\"\n",
    "        file_name_write=\"baseline-result.txt\"\n",
    "\n",
    "        #print(\"modelling started\")\n",
    "        main_dict,test_dict=model_building(file_name_writeread,file_name_write,smooth_factor)\n",
    "        #print(\"modelling done\")\n",
    "        Score_dict = calcvocabscore(main_dict,test_dict)\n",
    "        #print(\"calc score done\")\n",
    "        actual_class,predicted_class,classes_list=naive_bayes(file_name_writeread,file_name_write,main_dict,test_dict,Score_dict)\n",
    "        #print(\"naivebyes done\")\n",
    "        result_analysis(actual_class,predicted_class,experiment.strip(),classes_list)\n",
    "        #print(\"result analysis done\")\n",
    "    \n",
    "    print(\"Remaining words in Vocab: \\n\",new_vocab_len)\n",
    "    print(\"Accuracy: \\n\",accuracy_diffsmooth)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(new_vocab_len, accuracy_diffsmooth,linestyle='--', marker='o', color='b') \n",
    "    plt.xlabel('Number of words remaining in vocab')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(\"EXPERIMENT 4 RESULTS\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Program finished\")\n",
    "    \n",
    "#changing smoothing factor    \n",
    "elif experiment=='exp5':\n",
    "    \n",
    "    accuracy_diffsmooth=[]\n",
    "    list_val=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "    \n",
    "    file_name_writeread=\"model-2018.txt\"\n",
    "    file_name_write=\"baseline-result.txt\"\n",
    "    \n",
    "    for i in list_val:\n",
    "        \n",
    "        smooth_factor=i\n",
    "    \n",
    "        main_dict,test_dict=model_building(file_name_writeread,file_name_write,smooth_factor)\n",
    "        Score_dict = calcvocabscore(main_dict,test_dict)\n",
    "        actual_class,predicted_class,classes_list=naive_bayes(file_name_writeread,file_name_write,main_dict,test_dict,Score_dict)\n",
    "        result_analysis(actual_class,predicted_class,experiment.strip(),classes_list)\n",
    "    \n",
    "    print(\"Smooth Factor: \\n\",list_val)\n",
    "    print(\"Accuracy: \\n\",accuracy_diffsmooth)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(list_val, accuracy_diffsmooth,linestyle='--', marker='o', color='b') \n",
    "    plt.xlabel('Smooth Factor')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(\"EXPERIMENT 5 RESULTS\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Program finished\")\n",
    "else:\n",
    "    print(\"Incorrect experiment no. has beeen entered\")\n",
    "    print(\"Program finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
